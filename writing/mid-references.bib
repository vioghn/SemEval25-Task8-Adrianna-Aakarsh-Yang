@misc{wei2023chainofthoughtpromptingelicitsreasoning,
      title={Chain-of-Thought Prompting Elicits Reasoning in Large Language Models}, 
      author={Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Brian Ichter and Fei Xia and Ed Chi and Quoc Le and Denny Zhou},
      year={2023},
      eprint={2201.11903},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2201.11903}, 
}
@misc{hao2023reasoninglanguagemodelplanning,
      title={Reasoning with Language Model is Planning with World Model}, 
      author={Shibo Hao and Yi Gu and Haodi Ma and Joshua Jiahua Hong and Zhen Wang and Daisy Zhe Wang and Zhiting Hu},
      year={2023},
      eprint={2305.14992},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.14992}, 
}

@misc{wang2023selfconsistencyimproveschainthought,
      title={Self-Consistency Improves Chain of Thought Reasoning in Language Models}, 
      author={Xuezhi Wang and Jason Wei and Dale Schuurmans and Quoc Le and Ed Chi and Sharan Narang and Aakanksha Chowdhery and Denny Zhou},
      year={2023},
      eprint={2203.11171},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2203.11171}, 
}
@article{Ouyang_2024,
   title={An Empirical Study of the Non-determinism of ChatGPT in Code Generation},
   ISSN={1557-7392},
   url={http://dx.doi.org/10.1145/3697010},
   DOI={10.1145/3697010},
   journal={ACM Transactions on Software Engineering and Methodology},
   publisher={Association for Computing Machinery (ACM)},
   author={Ouyang, Shuyin and Zhang, Jie M. and Harman, Mark and Wang, Meng},
   year={2024},
   month=sep }

@misc{ding2024semcodertrainingcodelanguage,
      title={SemCoder: Training Code Language Models with Comprehensive Semantics Reasoning}, 
      author={Yangruibo Ding and Jinjun Peng and Marcus J. Min and Gail Kaiser and Junfeng Yang and Baishakhi Ray},
      year={2024},
      eprint={2406.01006},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.01006}, 
}
@misc{luo2023wizardcoderempoweringcodelarge,
      title={WizardCoder: Empowering Code Large Language Models with Evol-Instruct}, 
      author={Ziyang Luo and Can Xu and Pu Zhao and Qingfeng Sun and Xiubo Geng and Wenxiang Hu and Chongyang Tao and Jing Ma and Qingwei Lin and Daxin Jiang},
      year={2023},
      eprint={2306.08568},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2306.08568}, 
}

@misc{yao2023treethoughtsdeliberateproblem,
      title={Tree of Thoughts: Deliberate Problem Solving with Large Language Models}, 
      author={Shunyu Yao and Dian Yu and Jeffrey Zhao and Izhak Shafran and Thomas L. Griffiths and Yuan Cao and Karthik Narasimhan},
      year={2023},
      eprint={2305.10601},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.10601}, 
}

@InProceedings{10.1007/11871842_29,
author="Kocsis, Levente
and Szepesv{\'a}ri, Csaba",
editor="F{\"u}rnkranz, Johannes
and Scheffer, Tobias
and Spiliopoulou, Myra",
title="Bandit Based Monte-Carlo Planning",
booktitle="Machine Learning: ECML 2006",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="282--293",
abstract="For large state-space Markovian Decision Problems Monte-Carlo planning is one of the few viable approaches to find near-optimal solutions. In this paper we introduce a new algorithm, UCT, that applies bandit ideas to guide Monte-Carlo planning. In finite-horizon or discounted MDPs the algorithm is shown to be consistent and finite sample bounds are derived on the estimation error due to sampling. Experimental results show that in several domains, UCT is significantly more efficient than its alternatives.",
isbn="978-3-540-46056-5"
}

@inproceedings{oses-grijalba-etal-2024-question,
    title = "Question Answering over Tabular Data with {D}ata{B}ench: A Large-Scale Empirical Evaluation of {LLM}s",
    author = "Os{\'e}s Grijalba, Jorge  and
      Ure{\~n}a-L{\'o}pez, L. Alfonso  and
      Mart{\'\i}nez C{\'a}mara, Eugenio  and
      Camacho-Collados, Jose",
    editor = "Calzolari, Nicoletta  and
      Kan, Min-Yen  and
      Hoste, Veronique  and
      Lenci, Alessandro  and
      Sakti, Sakriani  and
      Xue, Nianwen",
    booktitle = "Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",
    month = may,
    year = "2024",
    address = "Torino, Italia",
    publisher = "ELRA and ICCL",
    url = "https://aclanthology.org/2024.lrec-main.1179",
    pages = "13471--13488",
    abstract = "Large Language Models (LLMs) are showing emerging abilities, and one of the latest recognized ones deals with their ability to reason and answer questions from tabular data. Although there are some available datasets to assess question answering systems on tabular data, they are not large and diverse enough to properly assess the capabilities of LLMs. To this end, we propose DataBench, a benchmark composed of 65 real-world datasets over several domains, including 20 human-generated questions per dataset, totaling 1300 questions and answers overall. Using this benchmark, we perform a large-scale empirical comparison of several open and closed source models, including both code-generating and in-context learning models. The results highlight the current gap between open-source and closed-source models, with all types of model having room for improvement even in simple boolean questions or involving a single column.",
}

@misc{chen2023teachinglargelanguagemodels,
      title={Teaching Large Language Models to Self-Debug}, 
      author={Xinyun Chen and Maxwell Lin and Nathanael Sch√§rli and Denny Zhou},
      year={2023},
      eprint={2304.05128},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2304.05128}, 
}

@misc{zhang2023planninglargelanguagemodels,
      title={Planning with Large Language Models for Code Generation}, 
      author={Shun Zhang and Zhenfang Chen and Yikang Shen and Mingyu Ding and Joshua B. Tenenbaum and Chuang Gan},
      year={2023},
      eprint={2303.05510},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2303.05510}, 
}

@misc{gao2024interpretablecontrastivemontecarlo,
      title={Interpretable Contrastive Monte Carlo Tree Search Reasoning}, 
      author={Zitian Gao and Boye Niu and Xuzheng He and Haotian Xu and Hongzhang Liu and Aiwei Liu and Xuming Hu and Lijie Wen},
      year={2024},
      eprint={2410.01707},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.01707}, 
}

@misc{sprague2024cotcotchainofthoughthelps,
      title={To CoT or not to CoT? Chain-of-thought helps mainly on math and symbolic reasoning}, 
      author={Zayne Sprague and Fangcong Yin and Juan Diego Rodriguez and Dongwei Jiang and Manya Wadhwa and Prasann Singhal and Xinyu Zhao and Xi Ye and Kyle Mahowald and Greg Durrett},
      year={2024},
      eprint={2409.12183},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2409.12183}, 
}

@misc{openai2024gpt4technicalreport,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2024},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2303.08774}, 
}


@misc{hao2024llmreasonersnewevaluation,
      title={LLM Reasoners: New Evaluation, Library, and Analysis of Step-by-Step Reasoning with Large Language Models}, 
      author={Shibo Hao and Yi Gu and Haotian Luo and Tianyang Liu and Xiyan Shao and Xinyuan Wang and Shuhua Xie and Haodi Ma and Adithya Samavedhi and Qiyue Gao and Zhen Wang and Zhiting Hu},
      year={2024},
      eprint={2404.05221},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.05221}, 
}